if [[ "$HOSTNAME" == gpatlas* ]]
then
	echo "Atlas local setup for gpatlas*"
    export ATLAS_LOCAL_ROOT_BASE=/cvmfs/atlas.cern.ch/repo/ATLASLocalRootBase
    source ${ATLAS_LOCAL_ROOT_BASE}/user/atlasLocalSetup.sh
    alias qme='qstat -u $USER'
    # utils from ~cshimmin/.bash_profile
    function qkill_all() {
        if [ -z "$1" ]; then
	        lim=200
        else
            lim=$1
        fi
	    # first kill the jobs which are queued
        jobids="$(qstat -u $(whoami) | grep atlas | grep Q | tail -n $lim | cut -d' ' -f1)"
	    if [ ! -z "$jobids" ]; then
		    qdel $jobids
        fi
	    # then kill any that are still running (squelch the usual error about 'all')
        qdel all 2> /dev/null
    }

    function qhold_all() {
	    if [ -z "$1" ]; then
	        lim=100
        else
	        lim=$1
        fi
	    # first get jobs which are queued
        jobids="$(qstat -u $(whoami) | grep atlas | grep Q | tail -n $lim | cut -d' ' -f1)"
        if [ ! -z "$jobids" ]; then
	        qhold -h u $jobids
        fi
    }

    function qrls_all() {
	    if [ -z "$1" ]; then
	        lim=100
        else
	        lim=$1
        fi
	    # first get jobs which are holding
        jobids="$(qstat -u $(whoami) | grep atlas | grep H | tail -n $lim | cut -d' ' -f1)"
	    if [ ! -z "$jobids" ]; then
	        qrls -h u $jobids
        fi
    }

    function cluster_run() {
        for i in {0..6}; do
        node=compute-9-$((2*i + 26))
        echo "running on ${node}"
        ssh $node $1
        echo
        done
    }
    function jobs_per_user() {
        squeue |  grep -v USER | awk 'NR >  1 {count[$4]++}END{for(j in count) print j," : "count[j]" jobs"}'
    }

fi
